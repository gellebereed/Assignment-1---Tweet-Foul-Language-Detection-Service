{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cde61c3b",
   "metadata": {},
   "source": [
    "# Offensive Language Detector — Training Notebook\n",
    "\n",
    "We train and compare **three classic text classifiers** on tweets:\n",
    "- **Logistic Regression**\n",
    "- **Linear SVM** (probability-calibrated)\n",
    "- **Complement Naive Bayes**\n",
    "\n",
    "All models share the **same TF-IDF features (unigrams + bigrams)** so the comparison is fair. We tune a **decision threshold** on a validation set to meet **Recall ≥ 0.80** and, among thresholds that satisfy this, we pick the one with the **highest Precision** (tie-break by F1). The best model is evaluated on the test set and saved as an artifact for the FastAPI service.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "88f6f5cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, json, numpy as np, pandas as pd\n",
    "from pathlib import Path\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.naive_bayes import ComplementNB\n",
    "from sklearn.calibration import CalibratedClassifierCV\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score, precision_recall_fscore_support, roc_auc_score,\n",
    "    average_precision_score, confusion_matrix\n",
    ")\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from joblib import dump\n",
    "\n",
    "ARTIFACTS = Path('artifacts'); ARTIFACTS.mkdir(exist_ok=True)\n",
    "SEED = 42\n",
    "np.random.seed(SEED)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5de0f8fa",
   "metadata": {},
   "source": [
    "## 1) Load data and create splits\n",
    "\n",
    "We use the **Kaggle “Hate Speech & Offensive Language”** dataset (`data/labeled_data.csv`) as the primary source.  \n",
    "Labels are mapped to our binary target:\n",
    "- **foul (1)** if `class ∈ {0, 1}` (hate/offensive)\n",
    "- **proper (0)** if `class = 2` (neiher)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22d51b07",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False Positives (pred foul, true proper):\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>416</th>\n",
       "      <td>Up early then a bitch driving to denton omg ca...</td>\n",
       "      <td>0.996118</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2780</th>\n",
       "      <td>&lt;USER&gt;: &lt;USER&gt; np big nig nig</td>\n",
       "      <td>0.995004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>260</th>\n",
       "      <td>No girls no hoes just me myself and I</td>\n",
       "      <td>0.990686</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4680</th>\n",
       "      <td>I would bitch about the weather being bipolar,...</td>\n",
       "      <td>0.980780</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1696</th>\n",
       "      <td>I'm jus a trill nicca mane</td>\n",
       "      <td>0.970349</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   text     score\n",
       "416   Up early then a bitch driving to denton omg ca...  0.996118\n",
       "2780                      <USER>: <USER> np big nig nig  0.995004\n",
       "260               No girls no hoes just me myself and I  0.990686\n",
       "4680  I would bitch about the weather being bipolar,...  0.980780\n",
       "1696                         I'm jus a trill nicca mane  0.970349"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False Negatives (pred proper, true foul):\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>665</th>\n",
       "      <td>&lt;USER&gt;: Scarlett Johansson &lt;URL&gt;</td>\n",
       "      <td>0.003365</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4440</th>\n",
       "      <td>&lt;USER&gt;: Trent Richardson so trash</td>\n",
       "      <td>0.011651</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>418</th>\n",
       "      <td>&lt;USER&gt; trash</td>\n",
       "      <td>0.020228</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1013</th>\n",
       "      <td>&lt;USER&gt; monkey dong</td>\n",
       "      <td>0.025542</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2771</th>\n",
       "      <td>Roy Hibbert so trash. It's unbelievable.</td>\n",
       "      <td>0.036012</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          text     score\n",
       "665           <USER>: Scarlett Johansson <URL>  0.003365\n",
       "4440         <USER>: Trent Richardson so trash  0.011651\n",
       "418                               <USER> trash  0.020228\n",
       "1013                        <USER> monkey dong  0.025542\n",
       "2771  Roy Hibbert so trash. It's unbelievable.  0.036012"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class ratio (foul=1): 0.832602757131059 0.8325711382113821 0.831783259199353\n",
      "Sizes: (15741, 2) (3936, 2) (4946, 2)\n"
     ]
    }
   ],
   "source": [
    "# --- Kaggle: Hate Speech & Offensive Language (Davidson et al.) ---\n",
    "# Expect CSV with columns: tweet, class (0=hate, 1=offensive, 2=neither)\n",
    "# Map to binary: foul=1 if class in {0,1}, else proper=0.\n",
    "\n",
    "import os, re, numpy as np, pandas as pd\n",
    "from pathlib import Path\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "ARTIFACTS = Path('artifacts'); ARTIFACTS.mkdir(exist_ok=True)\n",
    "SEED = 42\n",
    "np.random.seed(SEED)\n",
    "\n",
    "def find_csv():\n",
    "    \"\"\"Be tolerant about where the notebook was launched from.\"\"\"\n",
    "    candidates = [\n",
    "        Path(\"data/labeled_data.csv\"),\n",
    "        Path(\"../data/labeled_data.csv\"),\n",
    "        Path.cwd() / \"data\" / \"labeled_data.csv\",\n",
    "        Path.cwd().parent / \"data\" / \"labeled_data.csv\",\n",
    "        Path(\"labeled_data.csv\"),\n",
    "    ]\n",
    "    for p in candidates:\n",
    "        if p.exists():\n",
    "            return p\n",
    "    raise FileNotFoundError(f\"CSV not found. Tried: {[str(p) for p in candidates]}\")\n",
    "\n",
    "def load_offensive_dataset(csv_path=None):\n",
    "    csv_path = Path(csv_path) if csv_path else find_csv()\n",
    "    print(\"Using CSV:\", csv_path.resolve())\n",
    "\n",
    "    # latin-1 is common for this file; ignore bad lines if any\n",
    "    df = pd.read_csv(csv_path, encoding=\"latin-1\", on_bad_lines=\"skip\")\n",
    "\n",
    "    assert 'tweet' in df.columns, f\"'tweet' column missing. Columns: {list(df.columns)[:10]}\"\n",
    "    assert 'class' in df.columns, f\"'class' column missing. Columns: {list(df.columns)[:10]}\"\n",
    "\n",
    "    df = df[['tweet','class']].dropna().copy()\n",
    "    df['text'] = df['tweet'].astype(str)\n",
    "    df['label'] = df['class'].apply(lambda c: 1 if c in (0,1) else 0)\n",
    "    df['text'] = df['text'].str.strip()\n",
    "    df = df[df['text'].str.len() > 0]\n",
    "\n",
    "    # train/test split (we'll make validation from train)\n",
    "    tr, te = train_test_split(df[['text','label']], test_size=0.20,\n",
    "                              random_state=SEED, stratify=df['label'])\n",
    "    return tr.reset_index(drop=True), te.reset_index(drop=True)\n",
    "\n",
    "def basic_clean(text: str) -> str:\n",
    "    t = str(text)\n",
    "    t = t.replace(\"RT \", \" \")                         # drop RT marker\n",
    "    t = re.sub(r'https?://\\S+|www\\.\\S+', '<URL>', t)  # keep URL token\n",
    "    t = re.sub(r'@\\w+', '<USER>', t)                  # keep mention token\n",
    "    return t.strip()\n",
    "\n",
    "# Load + clean\n",
    "train_df, test_df = load_offensive_dataset()\n",
    "for df_ in (train_df, test_df):\n",
    "    df_['text'] = df_['text'].astype(str).map(basic_clean)\n",
    "\n",
    "# De-duplicate AFTER cleaning\n",
    "train_df = train_df[['text','label']].drop_duplicates().reset_index(drop=True)\n",
    "test_df  = test_df[['text','label']].drop_duplicates().reset_index(drop=True)\n",
    "\n",
    "# Make validation from train\n",
    "train_df, val_df = train_test_split(train_df, test_size=0.20,\n",
    "                                    random_state=SEED, stratify=train_df['label'])\n",
    "\n",
    "print(\"Class ratio (foul=1):\",\n",
    "      train_df['label'].mean(), val_df['label'].mean(), test_df['label'].mean())\n",
    "print(\"Sizes:\", train_df.shape, val_df.shape, test_df.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b777e755",
   "metadata": {},
   "source": [
    "## 2) Shared TF-IDF features\n",
    "We use the same feature extractor for all models: unigrams + bigrams, Unicode accent stripping, and sensible frequency cutoffs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7c9928d5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>TfidfVectorizer(max_df=0.95, min_df=2, ngram_range=(1, 2),\n",
       "                strip_accents=&#x27;unicode&#x27;)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">TfidfVectorizer</label><div class=\"sk-toggleable__content\"><pre>TfidfVectorizer(max_df=0.95, min_df=2, ngram_range=(1, 2),\n",
       "                strip_accents=&#x27;unicode&#x27;)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "TfidfVectorizer(max_df=0.95, min_df=2, ngram_range=(1, 2),\n",
       "                strip_accents='unicode')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfidf = TfidfVectorizer(\n",
    "    lowercase=True,\n",
    "    strip_accents='unicode',\n",
    "    ngram_range=(1,2),\n",
    "    min_df=2, max_df=0.95\n",
    ")\n",
    "tfidf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4075f0b",
   "metadata": {},
   "source": [
    "## 3) Helper functions for threshold tuning and metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "978f6fa6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def choose_threshold_for_recall(y_true, scores, target_recall=0.80):\n",
    "    \"\"\"Pick threshold with Recall ≥ target; among those, maximize Precision (tie-break by F1).\"\"\"\n",
    "    best = {'thr':0.5, 'prec':0.0, 'rec':0.0, 'f1':0.0}\n",
    "    for t in np.unique(np.round(scores, 4)):\n",
    "        y_hat = (scores >= t).astype(int)\n",
    "        p, r, f1, _ = precision_recall_fscore_support(y_true, y_hat, average='binary', zero_division=0)\n",
    "        if r >= target_recall:\n",
    "            if (p > best['prec']) or (p==best['prec'] and f1>best['f1']):\n",
    "                best = {'thr':float(t), 'prec':float(p), 'rec':float(r), 'f1':float(f1)}\n",
    "    return best\n",
    "\n",
    "def metrics_summary(y_true, y_hat, scores=None):\n",
    "    acc = accuracy_score(y_true, y_hat)\n",
    "    p_b, r_b, f1_b, _ = precision_recall_fscore_support(y_true, y_hat, average='binary', zero_division=0)\n",
    "    p_m, r_m, f1_m, _ = precision_recall_fscore_support(y_true, y_hat, average='macro', zero_division=0)\n",
    "    p_w, r_w, f_w, _ = precision_recall_fscore_support(y_true, y_hat, average='weighted', zero_division=0)\n",
    "    out = dict(accuracy=acc,\n",
    "               precision_binary=p_b, recall_binary=r_b, f1_binary=f1_b,\n",
    "               precision_macro=p_m,  recall_macro=r_m, f1_macro=f1_m,\n",
    "               precision_weighted=p_w, recall_weighted=r_w, f1_weighted=f_w)\n",
    "    if scores is not None:\n",
    "        out['roc_auc'] = roc_auc_score(y_true, scores)\n",
    "        out['pr_auc']  = average_precision_score(y_true, scores)\n",
    "    return out"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc3380bc",
   "metadata": {},
   "source": [
    "## 4) Build the three model pipelines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6a033b4c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['logreg', 'linear_svm', 'comp_nb']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Logistic Regression\n",
    "pipe_logreg = Pipeline([\n",
    "    ('tfidf', tfidf),\n",
    "    ('clf', LogisticRegression(max_iter=2000, solver='liblinear', class_weight='balanced'))\n",
    "])\n",
    "\n",
    "# Linear SVM + Platt scaling (probabilities via calibration)\n",
    "svm_base = LinearSVC(class_weight='balanced')\n",
    "pipe_svm = Pipeline([\n",
    "    ('tfidf', tfidf),\n",
    "    ('clf', CalibratedClassifierCV(svm_base, method='sigmoid', cv=3))\n",
    "])\n",
    "\n",
    "# Complement Naive Bayes\n",
    "pipe_cnb = Pipeline([\n",
    "    ('tfidf', tfidf),\n",
    "    ('clf', ComplementNB())\n",
    "])\n",
    "\n",
    "models = {\n",
    "    'logreg': pipe_logreg,\n",
    "    'linear_svm': pipe_svm,\n",
    "    'comp_nb': pipe_cnb\n",
    "}\n",
    "list(models.keys())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c73db4a8",
   "metadata": {},
   "source": [
    "## 5) Train each model and tune its decision threshold on the validation set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "dd58932e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training logreg ...\n",
      "logreg {\n",
      "  \"accuracy\": 0.8328252032520326,\n",
      "  \"precision_binary\": 0.9969639468690702,\n",
      "  \"recall_binary\": 0.8016478486420506,\n",
      "  \"f1_binary\": 0.888700947225981,\n",
      "  \"precision_macro\": 0.7486741333115527,\n",
      "  \"recall_macro\": 0.8947541215896141,\n",
      "  \"f1_macro\": 0.7764933307558477,\n",
      "  \"precision_weighted\": 0.9138221851137837,\n",
      "  \"recall_weighted\": 0.8328252032520326,\n",
      "  \"f1_weighted\": 0.8511273602067647,\n",
      "  \"roc_auc\": 0.9769321564794033,\n",
      "  \"pr_auc\": 0.9948078034771524,\n",
      "  \"threshold\": 0.7462\n",
      "}\n",
      "Training linear_svm ...\n",
      "linear_svm {\n",
      "  \"accuracy\": 0.8373983739837398,\n",
      "  \"precision_binary\": 0.9969845457972107,\n",
      "  \"recall_binary\": 0.8071406774488862,\n",
      "  \"f1_binary\": 0.8920741989881956,\n",
      "  \"precision_macro\": 0.7521945332259632,\n",
      "  \"recall_macro\": 0.8975005359930319,\n",
      "  \"f1_macro\": 0.7812585207093399,\n",
      "  \"precision_weighted\": 0.9150147194331598,\n",
      "  \"recall_weighted\": 0.8373983739837398,\n",
      "  \"f1_weighted\": 0.8549667132230706,\n",
      "  \"roc_auc\": 0.9798332332349946,\n",
      "  \"pr_auc\": 0.9951646492729794,\n",
      "  \"threshold\": 0.9478\n",
      "}\n",
      "Training comp_nb ...\n",
      "comp_nb {\n",
      "  \"accuracy\": 0.827489837398374,\n",
      "  \"precision_binary\": 0.9887133182844243,\n",
      "  \"recall_binary\": 0.801953005797986,\n",
      "  \"f1_binary\": 0.8855939342881213,\n",
      "  \"precision_macro\": 0.7404442960749196,\n",
      "  \"recall_macro\": 0.8782147426562009,\n",
      "  \"f1_macro\": 0.7675259294569156,\n",
      "  \"precision_weighted\": 0.9055785186726033,\n",
      "  \"recall_weighted\": 0.827489837398374,\n",
      "  \"f1_weighted\": 0.8460579509630376,\n",
      "  \"roc_auc\": 0.9592149820587041,\n",
      "  \"pr_auc\": 0.9908849419927738,\n",
      "  \"threshold\": 0.8377\n",
      "}\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>accuracy</th>\n",
       "      <th>precision_binary</th>\n",
       "      <th>recall_binary</th>\n",
       "      <th>f1_binary</th>\n",
       "      <th>precision_macro</th>\n",
       "      <th>recall_macro</th>\n",
       "      <th>f1_macro</th>\n",
       "      <th>precision_weighted</th>\n",
       "      <th>recall_weighted</th>\n",
       "      <th>f1_weighted</th>\n",
       "      <th>roc_auc</th>\n",
       "      <th>pr_auc</th>\n",
       "      <th>threshold</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>linear_svm</th>\n",
       "      <td>0.837398</td>\n",
       "      <td>0.996985</td>\n",
       "      <td>0.807141</td>\n",
       "      <td>0.892074</td>\n",
       "      <td>0.752195</td>\n",
       "      <td>0.897501</td>\n",
       "      <td>0.781259</td>\n",
       "      <td>0.915015</td>\n",
       "      <td>0.837398</td>\n",
       "      <td>0.854967</td>\n",
       "      <td>0.979833</td>\n",
       "      <td>0.995165</td>\n",
       "      <td>0.9478</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>logreg</th>\n",
       "      <td>0.832825</td>\n",
       "      <td>0.996964</td>\n",
       "      <td>0.801648</td>\n",
       "      <td>0.888701</td>\n",
       "      <td>0.748674</td>\n",
       "      <td>0.894754</td>\n",
       "      <td>0.776493</td>\n",
       "      <td>0.913822</td>\n",
       "      <td>0.832825</td>\n",
       "      <td>0.851127</td>\n",
       "      <td>0.976932</td>\n",
       "      <td>0.994808</td>\n",
       "      <td>0.7462</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>comp_nb</th>\n",
       "      <td>0.827490</td>\n",
       "      <td>0.988713</td>\n",
       "      <td>0.801953</td>\n",
       "      <td>0.885594</td>\n",
       "      <td>0.740444</td>\n",
       "      <td>0.878215</td>\n",
       "      <td>0.767526</td>\n",
       "      <td>0.905579</td>\n",
       "      <td>0.827490</td>\n",
       "      <td>0.846058</td>\n",
       "      <td>0.959215</td>\n",
       "      <td>0.990885</td>\n",
       "      <td>0.8377</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            accuracy  precision_binary  recall_binary  f1_binary  \\\n",
       "linear_svm  0.837398          0.996985       0.807141   0.892074   \n",
       "logreg      0.832825          0.996964       0.801648   0.888701   \n",
       "comp_nb     0.827490          0.988713       0.801953   0.885594   \n",
       "\n",
       "            precision_macro  recall_macro  f1_macro  precision_weighted  \\\n",
       "linear_svm         0.752195      0.897501  0.781259            0.915015   \n",
       "logreg             0.748674      0.894754  0.776493            0.913822   \n",
       "comp_nb            0.740444      0.878215  0.767526            0.905579   \n",
       "\n",
       "            recall_weighted  f1_weighted   roc_auc    pr_auc  threshold  \n",
       "linear_svm         0.837398     0.854967  0.979833  0.995165     0.9478  \n",
       "logreg             0.832825     0.851127  0.976932  0.994808     0.7462  \n",
       "comp_nb            0.827490     0.846058  0.959215  0.990885     0.8377  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_scores_table = {}\n",
    "for name, pipe in models.items():\n",
    "    print(f\"Training {name} ...\")\n",
    "    pipe.fit(train_df['text'], train_df['label'])\n",
    "    try:\n",
    "        scores_val = pipe.predict_proba(val_df['text'])[:,1]\n",
    "    except Exception:\n",
    "        z = pipe.decision_function(val_df['text'])\n",
    "        scores_val = 1.0/(1.0+np.exp(-z))\n",
    "    choice = choose_threshold_for_recall(val_df['label'].values, scores_val, 0.80)\n",
    "    preds_val = (scores_val >= choice['thr']).astype(int)\n",
    "    metrics = metrics_summary(val_df['label'].values, preds_val, scores=scores_val)\n",
    "    metrics.update(threshold=choice['thr'])\n",
    "    val_scores_table[name] = metrics\n",
    "    print(name, json.dumps(metrics, indent=2))\n",
    "\n",
    "val_scores_table\n",
    "\n",
    "# Save validation comparison across the 3 models\n",
    "val_table = (pd.DataFrame(val_scores_table)\n",
    "             .T\n",
    "             .sort_values(['precision_binary','f1_binary'], ascending=False))\n",
    "val_table.to_csv('artifacts/validation_model_compare.csv')\n",
    "val_table.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80d84e53",
   "metadata": {},
   "source": [
    "## 6) Pick a winner by precision (tie-break by F1), then evaluate on the test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3df4d15e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Winner on validation: linear_svm with threshold 0.9478\n",
      "Test metrics for linear_svm {\n",
      "  \"accuracy\": 0.8358269308532147,\n",
      "  \"precision_binary\": 0.9969897652016857,\n",
      "  \"recall_binary\": 0.8050559066601848,\n",
      "  \"f1_binary\": 0.8908015061861216,\n",
      "  \"precision_macro\": 0.7515737003348331,\n",
      "  \"recall_macro\": 0.8965183379454771,\n",
      "  \"f1_macro\": 0.7800913068389892,\n",
      "  \"precision_weighted\": 0.9144235840576416,\n",
      "  \"recall_weighted\": 0.8358269308532147,\n",
      "  \"f1_weighted\": 0.8535548883709926,\n",
      "  \"roc_auc\": 0.9811894948300364,\n",
      "  \"pr_auc\": 0.9960326156380565\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "cands = [(n, m['precision_binary'], m['f1_binary']) for n,m in val_scores_table.items()]\n",
    "cands.sort(key=lambda x: (x[1], x[2]), reverse=True)\n",
    "best_name = cands[0][0]\n",
    "best_threshold = val_scores_table[best_name]['threshold']\n",
    "best_model = models[best_name]\n",
    "print('Winner on validation:', best_name, 'with threshold', best_threshold)\n",
    "\n",
    "try:\n",
    "    scores_test = best_model.predict_proba(test_df['text'])[:,1]\n",
    "except Exception:\n",
    "    z = best_model.decision_function(test_df['text'])\n",
    "    scores_test = 1.0/(1.0+np.exp(-z))\n",
    "preds_test = (scores_test >= best_threshold).astype(int)\n",
    "test_metrics = metrics_summary(test_df['label'].values, preds_test, scores=scores_test)\n",
    "print('Test metrics for', best_name, json.dumps(test_metrics, indent=2))\n",
    "\n",
    "from sklearn.metrics import RocCurveDisplay, PrecisionRecallDisplay\n",
    "cm = confusion_matrix(test_df['label'].values, preds_test)\n",
    "fig = sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', cbar=False)\n",
    "plt.title(f'Confusion Matrix — {best_name}')\n",
    "plt.xlabel('Predicted'); plt.ylabel('True')\n",
    "plt.tight_layout(); plt.savefig(ARTIFACTS/'fig_cm.png', dpi=160); plt.close()\n",
    "RocCurveDisplay.from_predictions(test_df['label'].values, scores_test)\n",
    "plt.title(f'ROC — {best_name}')\n",
    "plt.tight_layout(); plt.savefig(ARTIFACTS/'fig_roc.png', dpi=160); plt.close()\n",
    "PrecisionRecallDisplay.from_predictions(test_df['label'].values, scores_test)\n",
    "plt.title(f'PR — {best_name}')\n",
    "plt.tight_layout(); plt.savefig(ARTIFACTS/'fig_pr.png', dpi=160); plt.close()\n",
    "\n",
    "pd.DataFrame([test_metrics]).to_csv('artifacts/test_metrics_winner.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecee97d2",
   "metadata": {},
   "source": [
    "## 7) Save the chosen pipeline + threshold for the FastAPI service"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4f8dea99",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved: artifacts\\model.joblib\n"
     ]
    }
   ],
   "source": [
    "artifact = {\n",
    "    'pipeline': best_model,\n",
    "    'threshold': float(best_threshold),\n",
    "    'label_map': {0: 'proper', 1: 'foul'},\n",
    "    'model_name': best_name,\n",
    "    'val_results': val_scores_table,\n",
    "    'test_metrics': test_metrics\n",
    "}\n",
    "dump(artifact, ARTIFACTS/'model.joblib')\n",
    "json.dump(test_metrics, open(ARTIFACTS/'metrics.json','w'), indent=2)\n",
    "print('Saved:', ARTIFACTS/'model.joblib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49156d75-1a94-4e08-8020-fb2ea2c1854c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
